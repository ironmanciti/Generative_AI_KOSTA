{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0159061-ae5d-49cb-8e0c-24a48087731c",
   "metadata": {},
   "source": [
    "# Text 생성 및 Prompt 예제\n",
    "\n",
    "- https://platform.openai.com/docs/examples 참조\n",
    "\n",
    "### Text 생성 API 비교\n",
    "| 특징                                                                                            | **Responses API**                                                         | **Chat Completions API**                                              |\r\n",
    "| --------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- | --------------------------------------------------------------------- |\r\n",
    "| **상태 유지(Stateful)**                                                                           | ✅ 서버 측에서 **대화 상태를 관리(저장 및 이어쓰기 가능)**                                      |                                                                                                                |                                                                       |\r\n",
    "| **내장 도구 지원(Built-in Tools)**                                                                  | ✅ `web_search`, `file_search`, `computer_use_preview` 등 자동 호출 가능          | ❌ 기본 제공 도구 없음. **Function calling은 가능하지만, 호출/실행은 직접 구현 필요**           |\r\n",
    "| **구조 & 사용 방식**                                                                                | `instructions`, `input`, `tools`, `store`, `previous_response_id` 기반 API  | `messages=[{role, content}, ...]`, `temperature`, `max_tokens`, 등의 구조 |\r\n",
    "| **응답 형식 (Output)**                                                                            | `response.output_text`, `response.output` 구조로 단일 메세지 응답 및 도구 호출 결과 포함     | `choices[0].message.content` 형태로 단일 응답만 반환                            |\r\n",
    "| **사용 목적**                                                                                     | ✅ **에이전트/도구 사용, 파일/웹 검색, 상태 관리**가 필요한 복잡한 워크플로우에 적합                       | ✅ **챗봇, 단순 대화, instruction-following**에 적합                            |\r\n",
    "| **미래 확장성**                                                                                    | 🔧 OpenAI Roadmap 중심 – Responses API가 Chat API의 기능을 통합 발전시키는 방향           | 📦 **기존 표준 API**, 계속 지원되며 업계 표준 유지                                    |\r\n",
    "\r\n",
    "[1]: https://simonwillison.net/2025/Mar/11/responses-vs-chat-completions/?utm_source=chatgpt.com \"OpenAI API: Responses vs. Chat Completions\"\r\n",
    "[2]: https://cookbook.openai.com/examples/responses_api/responses_example?utm_source=chatgpt.com \"Web Search and States with Responses API - OpenAI Cookbook\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d528baa-a3de-4acd-8c8a-e9c39d912ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989f8b65-992a-4c1c-b196-aa19cfff4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a83b1e3-b3f3-42f4-a73f-7bc62e3eb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "Model = \"gpt-5-nano\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc60f43-0f75-4759-970d-4f147e1cc50c",
   "metadata": {},
   "source": [
    "## Chat Completions API - Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f364b378-0c28-4f77-bad3-962aa45f5df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그녀는 시장에 가지 않았다.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=Model, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"당신은 문장을 받게 될 것이며, 당신의 임무는 그것을 표준 한국어로 변환하는 것입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"안갔어 시장에 그녀는.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 응답 결과 출력\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00e72f-a786-472f-b849-27bd21ea6b7c",
   "metadata": {},
   "source": [
    "## Responses API - New"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00626d-ca14-411b-898f-856309a98b6d",
   "metadata": {},
   "source": [
    "## 문법 수정\n",
    "\n",
    "SYSTEM : 당신은 문장을 받게 될 것이며, 당신의 임무는 그것을 표준 한국어로 변환하는 것입니다.  \n",
    "USER :   \n",
    "안갔어 시장에 그녀는."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c10186-4a28-4ac1-ab16-82ab61d96fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그녀는 시장에 가지 않았다.\n"
     ]
    }
   ],
   "source": [
    "# Responses API 호출 예시\n",
    "response = client.responses.create(\n",
    "    model=Model, \n",
    "    instructions=\"당신은 문장을 받게 될 것이며, 당신의 임무는 그것을 표준 한국어로 변환하는 것입니다.\",\n",
    "    input=\"안갔어 시장에 그녀는.\"\n",
    ")\n",
    "\n",
    "# 응답 결과 출력\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e843a1d-71a5-4e7a-af28-9ab4e9db941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_041c73851deca32900690e72d1c86481a2be4985d670204a7b',\n",
       " 'content': [ResponseOutputText(annotations=[], text='그녀는 시장에 가지 않았다.', type='output_text', logprobs=[])],\n",
       " 'role': 'assistant',\n",
       " 'status': 'completed',\n",
       " 'type': 'message'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489f1a3-305e-4ef8-8cc6-5964ada92da2",
   "metadata": {},
   "source": [
    "## 프롬프트 엔지니어링(Prompt Engineering)\n",
    "모델이 요구사항에 맞는 결과물을 안정적으로 생성하도록 효과적인 지시문(prompt)을 작성하는 과정입니다. \n",
    "- 일부 프롬프트 엔지니어링 기법은 모든 모델에서 공통적으로 유효\n",
    "- 모델마다 프롬프트를 해석하는 방식이 다르기 때문에, 최적의 결과를 얻으려면 모델별로 프롬프트를 조정해야 합니다.\n",
    "- 프로덕션 환경에서는 특정 모델의 특정 버전을 고정하여 일관된 동작을 유지하세요.\n",
    "\n",
    "### 모델 및 API 선택 \n",
    "Reasoning 모델(o3, GPT-5 등) 은 일반 Chat 모델과 다르게 동작하며, 특히 중요한 점은, Reasoning 모델은 Responses API를 사용할 때 훨씬 더 높은 성능과 “지적 추론 능력”을 보여준다는 것입니다.  \n",
    "$\\rightarrow$ 텍스트 생성(text generation) 관련 애플리케이션을 개발할 때는 기존의 Chat Completions API 대신 Responses API를 사용하는 것을 강력히 권장 \n",
    "\n",
    "### 메시지 역할(roles)과 지시문(instruction) \n",
    "\n",
    "instructions 파라미터와 메시지 역할(message roles) 을 함께 사용하면, 모델에게 서로 다른 수준의 권한(authority) 을 가진 지시문을 전달할 수 있습니다.  \n",
    "instructions 파라미터는 모델이 응답을 생성할 때 따라야 할 말투(tone), 목표(goals), 올바른 응답의 예시와 같은 전반적인 행동 지침을 제공합니다.  \n",
    "이렇게 전달된 지시문은 입력 프롬프트(input 매개변수)에 포함된 지시보다 우선순위가 더 높습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb07ddbf-77fe-4b03-973d-765ad01510bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필수는 아니지만 권장됩니다.  \n",
      "자동 세미콜론 삽입(ASI)으로 대부분 작동하지만, 예외가 있어 문제를 일으킬 수 있습니다.  \n",
      "특히 반환문, 시작이 [,(, /인 줄, 인라인 IIFE 등에서 주의가 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    reasoning={\"effort\": \"low\"},              # 추론 강도 설정 (낮은 수준)\n",
    "    instructions=\"세줄 이내로 답하세요.\",       \n",
    "    input=\"자바스크립트에서 세미콜론은 필수 항목인가요?\",  # 실제 질문\n",
    ")\n",
    "\n",
    "print(response.output_text)  # 모델의 최종 텍스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75815b6c-48a6-4064-b357-4adae12694ff",
   "metadata": {},
   "source": [
    "---------------\n",
    "위의 예시는 `input` 배열에서 다음과 같은 메시지를 사용하는 것과 거의 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ff37c0-0553-4b8b-84e2-8eace872aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필수는 아니다. 자바스크립트의 ASI로 끝에 세미콜론이 자동으로 삽입되는 경우가 많다.  \n",
      "\n",
      "하지만 특정 구문에서 의도와 다른 동작이 생길 수 있어, 명시적으로 세미콜론을 쓰는 것을 권장한다.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"세줄 이내로 답하세요.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"자바스크립트에서 세미콜론은 필수 항목인가요?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4415f-60b6-4308-aaf1-9f46dc634445",
   "metadata": {},
   "source": [
    "## 구조화되지 않은 데이터의 구문 분석\n",
    "SYSTEM : 구조화되지 않은 데이터가 제공되며 이를 CSV 형식으로 구문 분석하는 작업이 수행됩니다.  \n",
    "USER :   \n",
    "최근 발견된 행성 구크럭스(Goocrux)에서는 많은 과일이 발견됐다. 그곳에서 자라는 네오스키즐이 있는데, 보라색이고 사탕 맛이 납니다. 회색 빛이 도는 파란색 과일이고 매우 시큼하며 레몬과 약간 비슷한 로헤클(loheckles)도 있습니다. 포유닛은 밝은 녹색을 띠며 단맛보다 풍미가 더 좋습니다. 네온 핑크색 맛과 솜사탕 같은 맛이 나는 루프노바도 많이 있습니다. 마지막으로 글로울(glowls)이라는 과일이 있는데, 이 과일은 신맛과 부식성이 있는 매우 신맛과 쓴맛이 나며 옅은 오렌지색을 띠고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a90e4b6-10c7-48bc-9da2-e617b32cef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    instructions=\"구조화되지 않은 데이터가 제공되며 이를 CSV 형식으로 구문 분석하는 작업이 수행됩니다.\",\n",
    "    input=\"\"\"\n",
    "      최근 발견된 행성 구크럭스(Goocrux)에서는 많은 과일이 발견됐다. 그곳에서 자라는 네오스키즐이 있는데, 보라색이고 사탕 맛이 납니다. \n",
    "      회색 빛이 도는 파란색 과일이고 매우 시큼하며 레몬과 약간 비슷한 로헤클(loheckles)도 있습니다. 포유닛은 밝은 녹색을 띠며 단맛보다 풍미가 더 좋습니다. \n",
    "      네온 핑크색 맛과 솜사탕 같은 맛이 나는 루프노바도 많이 있습니다. 마지막으로 글로울(glowls)이라는 과일이 있는데, \n",
    "      이 과일은 신맛과 부식성이 있는 매우 신맛과 쓴맛이 나며 옅은 오렌지색을 띠고 있습니다.\n",
    "      이 데이터를 과일명, 색상, 맛으로 분석해 주세요.\n",
    "      \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e85a03c-135c-4908-b24e-622a0c408a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과일명,색상,맛\n",
      "네오스키즐,보라색,사탕 맛\n",
      "로헤클(loheckles),회색 빛이 도는 파란색,매우 시큼하며 레몬과 약간 비슷한\n",
      "포유닛,밝은 녹색,풍미가 강함\n",
      "루프노바,네온 핑크색,솜사탕 같은 맛\n",
      "글로울(glowls),옅은 오렌지색,매우 신맛과 쓴맛(부식성)\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ba846-9805-40fb-8710-a370d3d3ebd5",
   "metadata": {},
   "source": [
    "## 대화 상태를 수동으로 관리\n",
    "\n",
    "| 역할       | 설명                                                                                      |\r\n",
    "|------------|-------------------------------------------------------------------------------------------|\r\n",
    "| developer  | 애플리케이션 개발자가 제공한 지침. **user 메시지보다 우선적으로 처리**됩니다.              |\r\n",
    "| user       | 최종 사용자가 입력한 지침. developer 메시지보다 **우선순위가 낮습니다.**                  |\r\n",
    "| assistant  | 모델이 생성한 응답 메시지. 응답 결과는 이 역할로 반환됩니다.                              |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebf51e4-be6c-4860-9bc1-eb955adb67ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "간단히 말하면, 딥러닝은 머신러닝의 한 하위 분야로, 다층 신경망을 이용해 데이터를 직접 학습하고 표현을 자동으로 만들어내는 방식입니다. 주요 차이를 요약하면 다음과 같습니다.\n",
      "\n",
      "- 정의\n",
      "  - 머신러닝 ML: 데이터에서 패턴을 배우는 모든 방법의 모음. 선형 회귀, 의사결정나무, 랜덤포레스트, SVM 등 다양한 모델이 포함됩니다.\n",
      "  - 딥러닝 DL: 다층 신경망(깊은 신경망)을 사용해 특징 추출과 예측을 end-to-end로 학습하는 ML의 한 분야.\n",
      "\n",
      "- 특징과 학습 방식\n",
      "  - ML 일반: 특징(engineered features)을 먼저 사람이 설계해야 하는 경우가 많습니다. 모델이 비교적 단순하고 해석이 가능한 경우가 많습니다.\n",
      "  - DL: 데이터에서 자동으로 특징을 학습하고 표현을 점진적으로 추상화합니다. 대규모 데이터에서 특히 강력합니다.\n",
      "\n",
      "- 데이터와 계산 자원\n",
      "  - ML: 데이터가 비교적 작아도 잘 작동하는 경우가 많고, CPU 위주로도 충분합니다.\n",
      "  - DL: 대규모 데이터와 높은 계산 자원(GPU/TPU)이 필요합니다. 학습 시간이 길 수 있습니다.\n",
      "\n",
      "- 해석성\n",
      "  - ML: 모델의 동작을 비교적 쉽게 해석할 수 있는 경우가 많습니다(특히 선형/트리 기반 모델).\n",
      "  - DL: 보통 블랙박스에 가까워 해석이 어렵습니다. 특정 해석이 필요하면 추가 기법이 필요합니다.\n",
      "\n",
      "- 주로 쓰이는 영역\n",
      "  - DL: 이미지, 영상, 음성, 자연어처리처럼 고차원적이고 비정형 데이터에 강합니다.\n",
      "  - ML: 표 형식의 데이터나 적은 데이터 규모에서도 잘 작동하는 간단한 예측/분류 문제에 적합합니다.\n",
      "\n",
      "- 예시\n",
      "  - DL: CNN(이미지), RNN/LSTM/Transformer(시퀀스 데이터, NLP), 대규모 음성 인식 모델\n",
      "  - ML: 선형 회귀, 로지스틱 회귀, 의사결정나무, 랜덤포레스트, XGBoost, SVM 등\n",
      "\n",
      "- 언제 어떤 게 더 좋을까\n",
      "  - 데이터가 많고 비정형 데이터(이미지/음성/텍스트)라면 DL이 강력합니다.\n",
      "  - 데이터가 상대적으로 작고 해석이 중요하거나 간단한 문제라면 전통적인 ML이 더適합니다(효율적이고 빠름).\n",
      "\n",
      "필요하시면 특정 문제에 대해 어떤 방법이 적합한지 간단한 평가표를 같이 만들어 드리겠습니다. 예를 들어 데이터 유형, 크기, 해석 필요성 등에 따라 추천 모델을 정리해 드릴 수 있어요.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"안녕하세요. 무었을 도와드릴까요?\"},\n",
    "        {\"role\": \"user\", \"content\": \"딥러닝과 머신러닝의 차이점이 무었인가요?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0d9c0-12f4-4ed8-aaf8-a704505fcb98",
   "metadata": {},
   "source": [
    "## Keyword 추출 \n",
    "\n",
    "reasoning 객체의 속성 effort (예: \"low\")는 reasoning 토큰을 얼마나 할당해서 모델이 내부 사고를 할지 정도를 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99d0449-9850-4e25-b779-2e1041a1577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\"블랙 온 블랙 도자기(Black-on-Black ware)는 뉴멕시코 북부의 푸에블로 원주민 도자기 예술가들이 개발한 20세기 및 21세기 도자기 전통입니다. \n",
    "전통적인 환원 소성 블랙웨어는 푸에블로 예술가들에 의해 수세기 동안 만들어졌습니다. \n",
    "지난 세기의 흑색 자기는 표면이 매끄럽고 선택적 버니싱이나 내화 슬립을 적용하여 디자인을 적용한 제품입니다. \n",
    "또 다른 스타일은 디자인을 조각하거나 절개하고 융기된 부분을 선택적으로 연마하는 것입니다. \n",
    "여러 세대에 걸쳐 Kha'po Owingeh와 P'ohwhóge Owingeh 푸에블로의 여러 가족은 여주인 도예가들로부터 전수받은 기술을 사용하여 검은 바탕에 검은 도자기를 만들어 왔습니다. \n",
    "다른 푸에블로 출신의 예술가들도 검정색 바탕에 검정색 도자기를 제작했습니다. 몇몇 현대 예술가들은 조상의 도자기를 기리는 작품을 만들었습니다.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac052fa-6db9-4b98-a995-8fe8eb32ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    instructions=\"텍스트 블록이 제공되며, 당신의 임무는 텍스트 블록에서 키워드 목록을 추출하는 것입니다.\",\n",
    "    input=text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e9c970c-d280-4d5c-a4d8-bf9ab8ffe51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Black-on-Black ware (Black-on-Black pottery)\n",
      "- Pueblo pottery\n",
      "- New Mexico\n",
      "- Northern New Mexico\n",
      "- Puebloan / Pueblo artists\n",
      "- Kha'po Owingeh\n",
      "- P'ohwhóge Owingeh\n",
      "- Owingeh\n",
      "- burnishing\n",
      "- reduction firing\n",
      "- black surface / black-fired ware\n",
      "- smooth surface\n",
      "- slip (inlay/apply)\n",
      "- design (applied designs)\n",
      "- carving / incising\n",
      "- relief polishing / raised relief\n",
      "- women potters\n",
      "- generations / passed down techniques\n",
      "- 20th century\n",
      "- 21st century\n",
      "- contemporary artists / modern artists\n",
      "- ancestral pottery / honoring ancestral pottery\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c706ef-9a0c-4fe7-971e-d0d23b9c7e45",
   "metadata": {},
   "source": [
    "## Python 버그 수정 \n",
    "SYSTEM : Python 코드 조각이 제공되며, 귀하의 임무는 그 안의 버그를 찾아 수정하는 것입니다.  \n",
    "USER : \n",
    "```Python\n",
    "    import Random\n",
    "    a = random.randint(1,12)\n",
    "    b = random.randint(1,12)\n",
    "    for i in range(10):\n",
    "        question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "        answer = input(question)\n",
    "        if answer = a*b\n",
    "            print (Well done!)\n",
    "        else:\n",
    "            print(\"No.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb3b30a2-e794-45ec-bacb-2755457a65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm_code = \"\"\"\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+ a +\" x \"+  b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b6d7d7-83e5-4a1a-b70c-52a7ed01ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    instructions=\"Python 코드 조각이 제공되며, 귀하의 임무는 그 안의 버그를 찾아 수정하는 것입니다. 수정된 코드를 제시해 주세요.\",\n",
    "    input=pgm_code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad47733-b511-4f9d-acd9-e618ec019bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음과 같이 수정하면 됩니다. 주요 수정점: import коррект, 문자열 결합 시 형변환 필요, input 결과를 정수로 비교, 비교 연산자 사용.\n",
      "\n",
      "원래 의도대로 한 문제당 같은 a, b를 사용하려면:\n",
      "\n",
      "import random\n",
      "a = random.randint(1, 12)\n",
      "b = random.randint(1, 12)\n",
      "\n",
      "for i in range(10):\n",
      "    question = \"What is \" + str(a) + \" x \" + str(b) + \"? \"\n",
      "    answer = input(question)\n",
      "    try:\n",
      "        if int(answer) == a * b:\n",
      "            print(\"Well done!\")\n",
      "        else:\n",
      "            print(\"No.\")\n",
      "    except ValueError:\n",
      "        print(\"Please enter a number.\")\n",
      "\n",
      "참고로 매 문제마다 새로운 곱셈 값을 원하면 루프 안에서 a, b를 다시 정해주면 됩니다. 예:\n",
      "\n",
      "import random\n",
      "\n",
      "for i in range(10):\n",
      "    a = random.randint(1, 12)\n",
      "    b = random.randint(1, 12)\n",
      "    question = f\"What is {a} x {b}? \"\n",
      "    try:\n",
      "        answer = int(input(question))\n",
      "    except ValueError:\n",
      "        print(\"Please enter a number.\")\n",
      "        continue\n",
      "    if answer == a * b:\n",
      "        print(\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471099c0-0e56-48f8-97d4-ce7460d27184",
   "metadata": {},
   "source": [
    "## Program Code 설명 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "011734c9-7f36-4e8c-a625-be8f300a89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = \"\"\"\n",
    "class Log:\n",
    "    def __init__(self, path):\n",
    "        dirname = os.path.dirname(path)\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        f = open(path, \"a+\")\n",
    "\n",
    "        # Check that the file is newline-terminated\n",
    "        size = os.path.getsize(path)\n",
    "        if size > 0:\n",
    "            f.seek(size - 1)\n",
    "            end = f.read(1)\n",
    "            if end != \"\\n\":\n",
    "                f.write(\"\\n\")\n",
    "        self.f = f\n",
    "        self.path = path\n",
    "\n",
    "    def log(self, event):\n",
    "        event[\"_event_id\"] = str(uuid.uuid4())\n",
    "        json.dump(event, self.f)\n",
    "        self.f.write(\"\\n\")\n",
    "\n",
    "    def state(self):\n",
    "        state = {\"complete\": set(), \"last\": None}\n",
    "        for line in open(self.path):\n",
    "            event = json.loads(line)\n",
    "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
    "                state[\"complete\"].add(event[\"id\"])\n",
    "                state[\"last\"] = event\n",
    "        return state\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b6bbf7e-afcb-4c9e-9b51-12903c2e6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    instructions=\"당신에게는 코드 조각이 제공될 것이며, 당신의 임무는 그것을 간결한 방식으로 설명하는 것입니다. 한국어로 설명해 주세요.\",\n",
    "    input=codes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02de98df-b0de-44dd-86f0-dfa7b9e8b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 코드 조각은 로그를 줄(Line) 단위의 JSON으로 저장하는 간단한 로거 클래스입니다.\n",
      "\n",
      "주요 동작 요약\n",
      "- __init__(path)\n",
      "  - 주어진 경로의 디렉터리가 없으면 생성합니다.\n",
      "  - 로그 파일을 append 모드로 열고, 파일이 이미 있으면 마지막 줄이 개행으로 끝나는지 확인하여 없으면 추가로 개행을 붙입니다.\n",
      "  - 파일 핸들self.f와 경로 self.path를 저장합니다.\n",
      "  - 주의: dirname이 빈 문자열일 수 있는데, 이 경우 os.makedirs('', ...)는 실패할 수 있습니다. 필요 시 dirname 처리 보완 권장.\n",
      "\n",
      "- log(event)\n",
      "  - 이벤트에 _event_id 키를 UUID로 추가합니다.\n",
      "  - json.dump로 이벤트를 파일에 한 줄의 JSON으로 기록하고, 마지막에 개행('\\n')을 추가합니다.\n",
      "  - writes는 append 모드의 특성상 항상 파일의 끝에 추가됩니다. 기록 직후 flush를 추가해볼 수도 있습니다.\n",
      "\n",
      "- state()\n",
      "  - 파일의 모든 줄을 순회하며 각 줄을 JSON으로 파싱합니다.\n",
      "  - event[\"type\"]가 \"submit\"이고 event[\"success\"]가 True인 경우, 해당 event의 id를 complete 세트에 추가하고 last에 그 이벤트를 저장합니다.\n",
      "  - 최종적으로 { \"complete\": ..., \"last\": ... } 형태의 상태를 반환합니다.\n",
      "  - 주의: 이벤트에 \"type\" 키가 없으면 예외가 날 수 있으며, 파일 크기가 커지면 전체를 다시 읽는 비용이 큽니다.\n",
      "\n",
      "코드가 가진 주의점/개선 포인트\n",
      "- 동시성 문제: 여러 프로세스가 같은 파일에 쓰면 충돌 가능. 파일 락이나 로그 시스템(예: 파일 기반 락, 큐, 또는 DB)을 고려 필요.\n",
      "- 이벤트 포맷 가정: 이벤트는 \"type\", \"success\", \"id\" 등의 필드를 포함한다고 가정합니다. 다르면 KeyError 발생 가능.\n",
      "- dirname 처리: path가 상대 경로일 때 dirname이 빈 문자열일 수 있습니다. 이 경우 디렉터리 생성 코드가 문제를 일으킬 수 있어, 필요 시 if dirname: os.makedirs(dirname, exist_ok=True)로 방어하는 것이 좋습니다.\n",
      "- 리더/라이터 혼합: state()가 파일을 새로 읽는 방식이라 로그가 커지면 성능 이슈가 생깁니다. 필요 시 인덱싱이나 스트리밍 파서로 개선 권장.\n",
      "- 안정성: 기록 직후 flush를 호출하면 데이터 유실 위험을 줄일 수 있습니다. 또한 파일을 닫는 메서드나 컨텍스트 매니저를 제공하는 것이 좋습니다.\n",
      "- 인코딩/호환성: json 모듈 사용 시 인코딩을 명시적으로 utf-8로 다루는 것이 바람직합니다.\n",
      "\n",
      "간단한 의도 예\n",
      "- log({'type':'submit','success':True,'id':'123'})를 호출하면, 파일에 한 줄의 JSON 객체가 추가됩니다.\n",
      "- state()의 결과 예: {'complete': {'123', '456'}, 'last': {'type':'submit','success':True,'id':'456', ...}}. 이때 last는 마지막으로 성공한 submit 이벤트입니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dbea4fb-429b-404a-956f-308f2b6f0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    instructions=\"당신에게는 코드 조각이 제공될 것이며, 당신의 임무는 그것에 한국어 주석을 추가하는 것입니다.\",\n",
    "    input=codes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e53ee9d1-f224-430b-b5ea-3e5974f5bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 한국어 주석이 추가된 수정 버전입니다. 코드 동작은 원래 의도대로 유지하되, 누락 가능성이 있는 부분에 주석으로 설명을 덧붙였습니다. 또한 경로의 디렉토리가 없으면 만들고, 마지막에 개행이 없으면 추가하도록 보완했습니다.\n",
      "\n",
      "import os\n",
      "import json\n",
      "import uuid\n",
      "\n",
      "class Log:\n",
      "    def __init__(self, path):\n",
      "        # 로그 파일 경로에서 디렉토리 이름을 얻음\n",
      "        dirname = os.path.dirname(path)\n",
      "        # 디렉토리가 비어있지 않다면(경로에 디렉토리 부분이 있다면) 생성\n",
      "        if dirname:\n",
      "            os.makedirs(dirname, exist_ok=True)\n",
      "\n",
      "        # 파일을 append/read-write 모드로 오픈\n",
      "        f = open(path, \"a+\")\n",
      "\n",
      "        # 파일이 비어있지 않다면 마지막에 개행 문자가 있는지 확인\n",
      "        size = os.path.getsize(path)\n",
      "        if size > 0:\n",
      "            f.seek(size - 1)\n",
      "            end = f.read(1)\n",
      "            # 마지막 문자가 개행이 아니면 개행 문자 추가\n",
      "            if end != \"\\n\":\n",
      "                f.write(\"\\n\")\n",
      "\n",
      "        self.f = f\n",
      "        self.path = path\n",
      "\n",
      "    def log(self, event):\n",
      "        # 이벤트에 고유 ID를 추가하고 JSON 형태로 파일에 기록\n",
      "        event[\"_event_id\"] = str(uuid.uuid4())\n",
      "        json.dump(event, self.f)\n",
      "        self.f.write(\"\\n\")\n",
      "\n",
      "    def state(self):\n",
      "        # 로그 파일을 한 줄씩 읽어 상태를 계산\n",
      "        state = {\"complete\": set(), \"last\": None}\n",
      "        for line in open(self.path):\n",
      "            event = json.loads(line)\n",
      "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
      "                state[\"complete\"].add(event[\"id\"])\n",
      "                state[\"last\"] = event\n",
      "        return state\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1934098-ba94-4cce-a64b-0a46566f67c2",
   "metadata": {},
   "source": [
    "## 감성 분류기\n",
    "- 한개의 text 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9c959ce-c320-4ec9-8412-31152d6363ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=Model,\n",
    "    instructions=\"당신은 텍스트를 입력 받게 될 것이고, 당신의 임무는 텍스트의 감정을 긍정적, 중립적, 부정적으로 분류하는 것입니다.\",\n",
    "    input=\"나는 새로운 배트맨 영화가 좋습니다!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ceeeec9-dcb0-4dde-8752-73efa1a82163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f659121-d028-4f51-a30c-c192404f96f8",
   "metadata": {},
   "source": [
    "- 여러개의 text 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70289e8-3146-4107-b7aa-6d0b6dc39dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiments: 나는 새로운 배트맨 영화가 좋습니다!\n",
      "Sentiment: 긍정\n",
      "\n",
      "Sentiments: 오늘 날씨가 너무 안 좋네요.\n",
      "Sentiment: 부정적\n",
      "\n",
      "Sentiments: 커피 마시러 가는 길이 설레네요!\n",
      "Sentiment: 긍정적\n",
      "\n",
      "Sentiments: 회의가 너무 길고 지루했습니다.\n",
      "Sentiment: 부정적\n",
      "\n",
      "Sentiments: 점심으로 먹은 피자가 맛있었어요.\n",
      "Sentiment: 긍정적\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiments = [\n",
    "    \"나는 새로운 배트맨 영화가 좋습니다!\",\n",
    "    \"오늘 날씨가 너무 안 좋네요.\",\n",
    "    \"커피 마시러 가는 길이 설레네요!\",\n",
    "    \"회의가 너무 길고 지루했습니다.\",\n",
    "    \"점심으로 먹은 피자가 맛있었어요.\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "for sent in sentiments:\n",
    "    response = client.responses.create(\n",
    "        model=Model,\n",
    "        instructions=\"당신은 텍스트를 입력 받게 될 것이고, 당신의 임무는 텍스트의 감정을 긍정적, 중립적, 부정적으로 분류하는 것입니다.\",\n",
    "        input=sent\n",
    "    )\n",
    "    # 감정 분석 결과 저장\n",
    "    responses.append({\n",
    "        \"text\": sent,\n",
    "        \"sentiment\": response.output_text\n",
    "    })\n",
    "\n",
    "# 결과 출력\n",
    "for result in responses:\n",
    "    print(f\"Sentiments: {result['text']}\\nSentiment: {result['sentiment']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aee066-e4e5-4e29-894e-8519710a44c5",
   "metadata": {},
   "source": [
    "## 회의록 요약\n",
    "\n",
    "SYSTEM : 회의록이 제공되며 귀하의 임무는 다음과 같이 회의를 요약하는 것입니다.  \n",
    "\n",
    " -토론의 전반적인 요약  \n",
    " -행동항목(무엇을 해야 하는지, 누가 하는지)  \n",
    " -해당하는 경우 다음 회의에서 더 자세히 논의해야 할 주제 목록입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd249722-e848-4ce9-8e20-84103c525c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_minutes = \"\"\"\n",
    "회의 날짜: 2050년 3월 5일\n",
    " 미팅 시간: 오후 2시\n",
    " 위치: 은하계 본부 회의실 3B\n",
    "\n",
    " 참석자:\n",
    " - 캡틴 스타더스트\n",
    " - 퀘이사 박사\n",
    " - 레이디 네뷸라\n",
    " - 초신성 경\n",
    " - 혜성 씨\n",
    "\n",
    " 오후 2시 5분에 캡틴 스타더스트가 회의를 소집했습니다.\n",
    "\n",
    " 1. 새로운 팀원인 Ms. Comet에 대한 소개와 환영 인사\n",
    "\n",
    " 2. Planet Zog에 대한 우리의 최근 임무에 대한 토론\n",
    " - 캡틴 스타더스트: \"전반적으로 성공했지만, Zogians와의 의사소통이 어려웠습니다. 언어 능력을 향상시켜야 합니다.\"\n",
    " - 퀘이사 박사: \"동의합니다. 즉시 Zogian-영어 사전 작업을 시작하겠습니다.\"\n",
    " - Lady Nebula: \"Zogian 음식은 말 그대로 이 세상의 것이 아니었습니다! 우리는 배에서 Zogian 음식의 밤을 갖는 것을 고려해야 합니다.\"\n",
    "\n",
    " 3. 7구역 우주 해적 문제 해결\n",
    " - 초신성 경: \"이 해적들을 처리하려면 더 나은 전략이 필요합니다. 그들은 이번 달에 이미 세 척의 화물선을 약탈했습니다.\"\n",
    " - 스타더스트 선장: \"그 지역의 순찰을 늘리는 것에 대해 스타빔 제독과 이야기하겠습니다.\n",
    " - 퀘이사 박사: \"저는 우리 함선이 해적의 발각을 피하는 데 도움이 될 수 있는 새로운 은폐 기술을 연구하고 있습니다. 프로토타입을 완성하려면 몇 주가 더 필요할 것입니다.\"\n",
    "\n",
    " 4. 연례 은하계 베이크오프 검토\n",
    " - Lady Nebula: \"우리 팀이 대회에서 2위를 했다는 소식을 전해드리게 되어 기쁩니다! 우리 화성 머드 파이가 대박을 쳤어요!\"\n",
    " - 혜성 씨: \"내년에는 1위를 목표로 합시다. 제 생각에는 승자가 될 수 있을 것 같은 주피터 젤로의 비법이 있습니다.\"\n",
    "\n",
    " 5. 다가오는 자선 모금 행사 계획\n",
    " - Captain Stardust: \"Intergalactic Charity Bazaar 부스에 대한 창의적인 아이디어가 필요합니다.\"\n",
    " - Sir Supernova: \"'Dunk the Alien' 게임은 어때요? 외계인 복장을 한 자원봉사자에게 사람들이 물 풍선을 던지게 할 수 있어요.\"\n",
    " - 퀘이사 박사: \"승자에게 상금을 주는 '별 이름을 지어라' 퀴즈 게임을 준비할 수 있어요.\"\n",
    " - Lady Nebula: \"좋은 아이디어입니다, 여러분. 이제 보급품을 모으고 게임을 준비합시다.\"\n",
    "\n",
    " 6. 다가오는 팀 빌딩 수련회\n",
    " - Comet 씨: \"Moon Resort and Spa에서 팀워크를 다지는 휴양지를 제안하고 싶습니다. 최근 임무를 마친 후 유대감을 형성하고 휴식을 취할 수 있는 좋은 기회입니다.\"\n",
    " - 캡틴 스타더스트: \"환상적인 생각이군요. 예산을 확인해 보고 실현할 수 있는지 알아보겠습니다.\"\n",
    "\n",
    " 7. 차기회의 안건\n",
    " - Zogian-English 사전 업데이트 (Dr. Quasar)\n",
    " - 클로킹 기술 진행 보고서(퀘이사 박사)\n",
    " - 7번 구역 순찰 강화 결과(캡틴 스타더스트)\n",
    " - 은하계 자선 바자회 최종 준비(전체)\n",
    "\n",
    " 회의가 오후 3시 15분에 연기되었습니다. 다음 회의는 2050년 3월 19일 오후 2시에 은하계 본부 회의실 3B에서 열릴 예정입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5fc8f65-0e84-48b9-bbe3-00375b70c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=Model,\n",
    "  instructions= \"\"\"\n",
    "          회의록이 제공되며 귀하의 임무는 다음과 같이 회의를 요약하는 것입니다.  \n",
    "             -토론의 전반적인 요약  \n",
    "             -행동항목(무엇을 해야 하는지, 누가 하는지)  \n",
    "             -해당하는 경우 다음 회의에서 더 자세히 논의해야 할 주제 목록입니다.  \n",
    "      \"\"\",\n",
    "  input=meeting_minutes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affce61e-6787-4e68-a663-1b2d12be7242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음은 회의록 요약입니다.\n",
      "\n",
      "전반적 요약\n",
      "- 회의 일시/장소: 2050년 3월 5일 오후 2시, 은하계 본부 회의실 3B\n",
      "- 참석자: 캡틴 스타더스트, 퀘이사 박사, 레이디 네뷸라, 초신성 경, 혜성 씨, 신규 멤버 Ms. Comet(소개)\n",
      "- 주요 논의 내용\n",
      "  1) 새로운 팀원 Ms. Comet의 소개 및 환영\n",
      "  2) Planet Zog 임무 재검토: 의사소통 문제 해소 필요\n",
      " 3) 다섯 구역 7번의 우주 해적 문제 대응 전략 논의\n",
      " 4) 연례 은하계 베이크오프 성과 공유 및 향후 목표\n",
      " 5) 다가오는 자선 모금 행사 기획 아이디어 확정\n",
      " 6) 다가오는 팀 빌딩 수련회 제안 및 예산 확인\n",
      " 7) 차기 회의 안건 정리 및 배분\n",
      "- 결론: 전반적으로 임무 성과는 긍정적이지만 의사소통, 탐지/은폐 기술, 해적 대응력 강화 등의 보완이 필요하다는 의견이 모아졌고, 다음 회의에서 각 주제를 구체적으로 진전시키기로 함. 회의는 3시 15분에 연기되어 재합의되었고, 다음 회의 일정은 2050년 3월 19일 오후 2시, 같은 장소로 확정됨.\n",
      "\n",
      "행동 항목(누가, 무엇을, 언제)\n",
      "- Ms. Comet 온보딩 및 공식 소개\n",
      "  - 책임: 캡틴 스타더스트\n",
      "  - 내용: 신규 팀원 Ms. Comet의 공식 소개 및 온보딩 자료 정리\n",
      "  - 기한: 오늘 회의에서 환영 인사 완료, 이후 온보딩 문서 업데이트\n",
      "\n",
      "- Planet Zog 임무: 언어 의사소통 강화\n",
      "  - 책임: 퀘이사 박사\n",
      "  - 내용: Zogian-English 사전 작업 시작 및 초기 초안 공유\n",
      "  - 기한: 다음 회의에서 진행 상황 보고\n",
      "\n",
      "- Zogian 음식 문화 행사 제안\n",
      "  - 책임: 레이디 네뷸라\n",
      "  - 내용: Zogian 음식 밤 행사 계획 제안 및 실행 가능성 검토\n",
      "  - 기한: 다음 회의 전 제안 계획 제출\n",
      "\n",
      "- 7구역 우주 해적 문제 대응\n",
      "  - 순찰 강화 협의\n",
      "    - 책임: 캡틴 스타더스트\n",
      "    - 내용: 스타빔 제독과의 순찰 강화 협의 추진\n",
      "    - 기한: 가능한 빠른 시일 내\n",
      "  - 은폐 기술 개발\n",
      "    - 책임: 퀘이사 박사\n",
      "    - 내용: 해적 발각을 피하는 새로운 은폐 기술 연구\n",
      "    - 기한: 프로토타입 완성은 몇 주 후, 이후 진행 상황 보고\n",
      "\n",
      "- 연례 은하계 베이크오프: 향후 목표 설정\n",
      "  - 책임: 혜성 씨\n",
      "  - 내용: 주피터 젤로 레시피 개발 및 대회 준비\n",
      "  - 기한: 차기 대회 준비 상황 다음 회의에서 보고\n",
      "\n",
      "- 다가오는 자선 모금 행사 계획\n",
      "  - 부스 아이디어 확정\n",
      "    - 책임: 캡틴 스타더스트\n",
      "    - 내용: Intergalactic Charity Bazaar 부스의 창의적 아이디어 확정\n",
      "  - 게임 아이디어 구체화\n",
      "    - 책임: Sir Supernova\n",
      "    - 내용: “Dunk the Alien” 게임 제안 및 운영 계획\n",
      "  - 퀴즈 아이디어 확정\n",
      "    - 책임: 퀘이사 박사\n",
      "    - 내용: “별 이름을 지어라” 퀴즈 게임 준비\n",
      "  - 보급품 및 준비물 확보\n",
      "    - 책임: 레이디 네뷸라\n",
      "    - 내용: 보급품 모으기 및 행사 준비\n",
      "  - 기한: 차기 회의 전까지 아이디어 구체화와 초기 자원 확보\n",
      "\n",
      "- 다가오는 팀 빌딩 수련회\n",
      "  - 제안: Moon Resort and Spa\n",
      "  - 책임: Ms. Comet\n",
      "  - 내용: 휴양지 제안 및 프로그램 구상\n",
      "  - 예산 확인 및 실행 가능성 확인\n",
      "  - 기한: 예산 확인 후 실행 여부 최종 결정\n",
      "\n",
      "- 차기 회의 안건(주요 발표자)\n",
      "  - Zogian-English 사전 업데이트: Dr. Quasar\n",
      "  - 클로킹 기술 진행 보고: Dr. Quasar\n",
      "  - 7번 구역 순찰 강화 결과: Captain Stardust\n",
      "  - 은하계 자선 바자회 최종 준비: 전체\n",
      "\n",
      "다음 회의 정보\n",
      "- 일정: 2050년 3월 19일 오후 2시\n",
      "- 장소: 은하계 본부 회의실 3B\n",
      "- 비고: 회의는 오후 3시 15분에 연기되었으며, 모든 안건의 진행 상황은 그 사이에 업데이트될 예정\n",
      "\n",
      "다음 회의에서 자세히 다룰 주제(권고)\n",
      "- Zogian-English 사전 업데이트의 진척 상황 및 초기 용례 샘플\n",
      "- Cloaking 기술의 실용화 가능성과 현 단계 프로토타입 시연 계획\n",
      "- 7번 구역 순찰 강화의 중간 평가 및 필요 자원\n",
      "- 은하계 자선 바자회의 최종 운영 계획 및 예산 분배 확정\n",
      "\n",
      "원하시면 이 요약을 바탕으로 각 항목에 대해 더 상세한 액션 플랜(마일스톤, 담당자 연락처, 필요 자원)을 추가로 정리해 드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e064629-07fc-4c86-bcf8-05d1bcdcb6da",
   "metadata": {},
   "source": [
    "## 이모티콘 번역\n",
    "SYSTEM : 텍스트가 제공되며, 귀하의 임무는 이를 이모티콘으로 번역하는 것입니다. 일반 텍스트를 사용하지 마십시오. 이모티콘만으로 최선을 다하세요.  \n",
    "USER : 인공지능은 큰 가능성을 지닌 기술이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e853f14d-436d-4da9-bce2-204f3a557f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "  model=Model,\n",
    "  instructions=\"텍스트가 제공되며, 귀하의 임무는 이를 이모티콘으로 번역하는 것입니다. 일반 텍스트를 사용하지 마십시오. 이모티콘만으로 최선을 다하세요.\",\n",
    "  input=\"인공지능은 큰 가능성을 지닌 기술이다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc850d0e-fbbd-4514-9594-dff865839b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖💡🚀✨💻\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd2c83-3e39-456a-a45d-56ca3fcf3bd5",
   "metadata": {},
   "source": [
    "## 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e11fee7-150b-43e7-ba53-4458c98c2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "  model=Model,\n",
    "  instructions=\"당신은 영어로 된 문장을 받게 될 것이고, 당신의 임무는 그것을 한국어와 동시에 일본어로 번역하는 것입니다.\",\n",
    "  input=\"My name is Jane. What is yours?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "551cc4f5-80d6-4218-bc56-932cf77b0d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean: 제 이름은 제인입니다. 당신의 이름은 무엇인가요?\n",
      "Japanese: 私の名前はジェーンです。あなたの名前は何ですか？\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47062606-7e80-4332-9bbc-f48681169d83",
   "metadata": {},
   "source": [
    "----------------\n",
    "## GPT-5 parameters\n",
    "\n",
    "- verbosity 제어 — 모델이 얼마나 자세하게 응답할지를 조정 (high, medium, low) \n",
    "- reasoning effort — 최소한의 추론 단계를 거쳐 빠른 응답 제공 (high, medium, low)  \n",
    "- custom tools — 개발자가 직접 정의한 맞춤형 도구 사용 가능  \n",
    "- allowed tools list — 모델이 사용할 수 있는 도구 목록을 제한하여 안전성 강화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "153ef2b1-9ba7-4da6-963a-77a52b07212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "42.\n",
      "\n",
      "Douglas Adams의 소설 “은하수를 여행하는 히치하이커를 위한 안내서”에서 초지능 컴퓨터 ‘딥 소트(Deep Thought)’가 750만 년 계산해 내놓은 답이 바로 이 숫자죠. 하지만 정작 그들이 몰랐던 건 “궁극적인 질문”이 무엇인지였고, 그 질문을 찾기 위해 지구 자체가 거대한 컴퓨터로 설계되었다는 설정의 농담입니다. 핵심은 “답”보다 “올바른 질문”을 찾는 일이 더 중요하다는 풍자예요. (그리고 여행에는 수건이 필수라는 것도요!)\n",
      "\n",
      "만약 농담이 아니라 진지하게 “삶의 의미”를 이야기하고 싶으시다면, 이런 관점들 중에서 함께 풀어볼 수 있어요:\n",
      "- 실존주의: 스스로 선택과 행동으로 의미를 만들어간다.\n",
      "- 아리스토텔레스적 번영: 타고난 잠재와 덕을 발휘해 번영하는 삶.\n",
      "- 관계와 기여: 타인과 공동체에 기여하면서 의미를 느낀다.\n",
      "- 과학적·진화적 관점: 보편적 의미는 없고, 인간이 의미를 부여한다.\n",
      "\n",
      "어떤 방향으로 더 이야기해 볼까요? 원하는 관점이나 지금 처한 상황을 알려주시면 거기에 맞춰 구체적으로 함께 정리해 드릴게요.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"삶, 우주, 그리고 모든 것에 대한 궁극적인 질문의 답은 무엇인가요?\",\n",
    "    text={\n",
    "        \"verbosity\": \"low\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------\\n\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"삶, 우주, 그리고 모든 것에 대한 궁극적인 질문의 답은 무엇인가요?\",\n",
    "    text={\n",
    "        \"verbosity\": \"high\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1a2bc59-c8c1-4547-8376-df84186703fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대략적인 추정치로 답하겠습니다. 자유의 여신상(뉴욕)은 내부가 비어 있고, 겉면은 구리판으로 이루어진 조형물입니다. 겉면 전체를 금 두께 1 mm로 균일하게 도금한다고 가정하면, 필요한 금의 부피는 표면적 × 두께로 구할 수 있습니다.\n",
      "\n",
      "- 자유의 여신상 외피 표면적(구리 외피 면적) 추정: 약 2,500–3,000 m²로 알려져 있습니다. 보수적으로 3,000 m² 사용.\n",
      "- 도금 두께: 1 mm = 0.001 m\n",
      "- 금 부피: 3,000 m² × 0.001 m = 3 m³\n",
      "- 금의 밀도: 약 19,300 kg/m³\n",
      "\n",
      "필요한 금의 질량:\n",
      "- 3 m³ × 19,300 kg/m³ ≈ 57,900 kg ≈ 58톤\n",
      "\n",
      "비용 감(참고):\n",
      "- 금 1톤 = 32,150 troy oz\n",
      "- 58톤 ≈ 1,865,000 troy oz\n",
      "- 금 시세가 예를 들어 2,400 USD/oz라면 총 비용은 약 45억 달러 규모\n",
      "\n",
      "주의:\n",
      "- 표면적 추정치에 따라 ±20% 정도 변동 가능 (표면적 2,500 m²라면 약 48톤, 3,500 m²라면 약 68톤).\n",
      "- 실제 도금은 구조·접합부·두께 편차·손실 등을 고려하면 더 많이 필요할 수 있습니다.\n",
      "\n",
      "----------------------------------------------------------\n",
      "\n",
      "대략 2.5만 kg(약 25톤), 부피로는 약 1.3 m³의 금이 필요합니다.\n",
      "\n",
      "간단한 근거\n",
      "- 가정: 받침대 제외, 외부 표면 전체를 1 mm 두께로 도금.\n",
      "- 자유의 여신상 외피(동판) 정보: 두께 ≈ 2.38 mm(3/32인치), 동 무게 ≈ 62,000 lb ≈ 28,100 kg.\n",
      "- 동 밀도 ≈ 8,960 kg/m³ → 표면적 ≈ (28,100)/(8,960×0.00238) ≈ 1.32×10³ m².\n",
      "- 금 도금 1 mm(0.001 m) → 금 부피 ≈ 1.32 m³.\n",
      "- 금 밀도 ≈ 19,320 kg/m³ → 금 질량 ≈ 1.32×19,320 ≈ 25,000 kg(≈25톤).\n",
      "\n",
      "참고\n",
      "- 실제 표면 굴곡, 겹침, 장식(왕관·횃불) 처리 방식에 따라 ±10~20% 정도 오차가 있을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"자유의 여신상을 두께 1mm의 금으로 도금하려면 금이 얼마나 필요할까요?\",\n",
    "    reasoning={\n",
    "        \"effort\": \"minimal\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------\\n\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"자유의 여신상을 두께 1mm의 금으로 도금하려면 금이 얼마나 필요할까요?\",\n",
    "    reasoning={\n",
    "        \"effort\": \"high\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2ab94-19a8-43ae-a80f-c2fedfaa8ca4",
   "metadata": {},
   "source": [
    "### Token 수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c6365c9-4e9e-4157-8d45-4672887d9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cee4fdf6-8911-48f4-8964-947aa6ffff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'o200k_base'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-5-nano\")\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea0a6f75-bab2-4f72-858d-eb8c3c4fc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATML_START = \"<|im_start|>\"\n",
    "CHATML_END = \"<|im_end|>\"\n",
    "\n",
    "def serialize_messages_chatml(messages: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    messages: [{\"role\": \"system\"|\"user\"|\"assistant\", \"content\": str, \"name\": optional str}, ...]\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for m in messages:\n",
    "        role = m.get(\"role\", \"user\")\n",
    "        name = m.get(\"name\")\n",
    "        header = f\"{role}\"\n",
    "        if name:\n",
    "            # 일부 모델은 name 지원. 표기는 role 다음 줄에 name: ... 형태로 덧붙여 직렬화 가능\n",
    "            header += f\"\\nname={name}\"\n",
    "        content = m.get(\"content\", \"\")\n",
    "        parts.append(f\"{CHATML_START}{header}\\n{content}{CHATML_END}\\n\")\n",
    "    # 최종 assistant 답변의 프롬프트 마커(모델에 따라 선택적으로 사용)\n",
    "    parts.append(f\"{CHATML_START}assistant\\n\")\n",
    "    return \"\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e75cffdd-9b6f-484d-bd94-15fcf1aca249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14307, 171731, 0, 68258, 118101, 8963, 4831, 173939, 5650, 43714, 227, 5637, 2276, 13, 6548, 26387, 112033, 52971, 5959, 28065, 8021, 27001, 13]\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "txt = \"안녕하세요! 토큰 수를 계산해봅시다. 이 문장은 한국어 예제입니다.\"\n",
    "\n",
    "print(enc.encode(txt))\n",
    "print(len(enc.encode(txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bf0819d-7711-4daa-a5c6-240b2e98300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant that replies in Korean.<|im_end|>\\n<|im_start|>user\\nopenai api 토큰 수를 계산하는 방법을 알려줘.<|im_end|>\\n<|im_start|>assistant\\ntiktoken을 사용하면 됩니다. 예제를 보여드릴게요.<|im_end|>\\n<|im_start|>user\\n채팅 메시지 배열의 토큰도 세줄 수 있나요?<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that replies in Korean.\"},\n",
    "        {\"role\": \"user\", \"content\": \"openai api 토큰 수를 계산하는 방법을 알려줘.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"tiktoken을 사용하면 됩니다. 예제를 보여드릴게요.\"},\n",
    "        {\"role\": \"user\", \"content\": \"채팅 메시지 배열의 토큰도 세줄 수 있나요?\"},\n",
    "    ]\n",
    "\n",
    "serialized = serialize_messages_chatml(messages)\n",
    "serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84dd3b2f-a65f-4bf9-93af-13977fd32dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc.encode(serialized))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
