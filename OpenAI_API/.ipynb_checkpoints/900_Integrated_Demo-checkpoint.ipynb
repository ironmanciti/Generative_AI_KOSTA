{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“˜ Integrated OpenAI API Demo â€” Mini Research Assistant\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ **í•˜ë‚˜ì˜ ì‘ìš© ì‹œë‚˜ë¦¬ì˜¤** ì†ì—ì„œ OpenAI APIì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„\n",
        "ìì—°ìŠ¤ëŸ½ê²Œ **ì¡°í•©**í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤. CLIê°€ ì•„ë‹Œ, **í•™ìŠµìš© ë…¸íŠ¸ë¶**\n",
        "í˜•íƒœë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´ ê°•ì˜/êµì¬ìš©ìœ¼ë¡œ ë°”ë¡œ í™œìš©í•˜ê±°ë‚˜ íŒŒíŠ¸ë³„ë¡œ ë¶„ë¦¬í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.\n",
        "\n",
        "## í¬í•¨ ê¸°ëŠ¥\n",
        "1. **Structured Output (Pydantic)**: ì£¼ì œ ìš”ì²­ì„ **í”„ë¡œì íŠ¸ ë¸Œë¦¬í”„** ìŠ¤í‚¤ë§ˆë¡œ êµ¬ì¡°í™”\n",
        "2. **Conversation State**: ì´ì „ ì‘ë‹µì„ ì´ì–´ë°›ì•„ **ë¬¸ë§¥ ìœ ì§€**\n",
        "3. **Web Search Tool**: ìµœì‹  ì •ë³´/ì¶œì²˜ **ê²€ìƒ‰ê³¼ ì¸ìš©**\n",
        "4. **File Search / Vector Store (RAG)**: ë¡œì»¬ í´ë” ë¬¸ì„œ ì¸ë±ì‹± í›„ **ê·¼ê±° ê¸°ë°˜ ë‹µë³€**\n",
        "5. **Code Interpreter**: ê°„ë‹¨í•œ ë°ì´í„° ê³„ì‚°/ì‹œê°í™”(ì˜ˆì œ) ìˆ˜í–‰\n",
        "6. **Function Calling**: ë³´ì¡° ë„êµ¬(ë‚ ì”¨/ì¼ì • ë“±) í˜¸ì¶œ â†’ ê²°ê³¼ ì¬ì£¼ì… â†’ ìµœì¢… ìš”ì•½\n",
        "7. **Streaming**: ìµœì¢… ë¦¬í¬íŠ¸ ìš”ì•½ì„ í† í° ë‹¨ìœ„ë¡œ **ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥**\n",
        "\n",
        "## ì‹œë‚˜ë¦¬ì˜¤\n",
        "í•™ìƒì€ ê´€ì‹¬ ì£¼ì œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤(ì˜ˆ: *\"í•œêµ­ ë°˜ë„ì²´ ì‚°ì—…ì—ì„œ AIê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥\"*).\n",
        "1) ì…ë ¥ì„ êµ¬ì¡°í™”í•´ í”„ë¡œì íŠ¸ ê°œìš”ë¥¼ ë§Œë“¤ê³ , 2) ì›¹ì—ì„œ ê´€ë ¨ ì¶œì²˜ë¥¼ ìˆ˜ì§‘í•˜ê³ ,\n",
        "3) ë¡œì»¬ ìë£Œ(RAG)ë„ ê²€ìƒ‰í•´ ì¸ìš©í•˜ë©°, 4) ê°„ë‹¨í•œ ìˆ˜ì¹˜ ì‹¤í—˜/ì°¨íŠ¸ë¥¼ ì½”ë“œ ì¸í„°í”„ë¦¬í„°ë¡œ\n",
        "ë§Œë“  ë‹¤ìŒ, 5) í•„ìš”ì‹œ í•¨ìˆ˜ í˜¸ì¶œ(ì˜ˆ: ì§€ì—­ ë‚ ì”¨) ê²°ê³¼ë„ ê²°í•©í•˜ì—¬, 6) ë¬¸ë§¥ì„ ì‡ëŠ” ëŒ€í™”\n",
        "íë¦„ ì†ì—ì„œ, 7) ìµœì¢… ìš”ì•½ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%capture\n",
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜(í™˜ê²½ì— ë”°ë¼ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ ìƒëµ ê°€ëŠ¥)\n",
        "!pip install -q openai python-dotenv pydantic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) ì¤€ë¹„: API í‚¤ ë¡œë“œ ë° í´ë¼ì´ì–¸íŠ¸ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, time\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI()\n",
        "\n",
        "# ê¸°ë³¸ ëª¨ë¸: í•„ìš” ì‹œ í™˜ê²½ë³€ìˆ˜ OPENAI_MODEL ë¡œ ì˜¤ë²„ë¼ì´ë“œ\n",
        "CHAT_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
        "\n",
        "# ì „ì—­ ìƒíƒœ (ê°„ë‹¨ ë°ëª¨ìš©)\n",
        "previous_response_id: Optional[str] = None\n",
        "vector_store_id: Optional[str] = None\n",
        "\n",
        "print(\"Model:\", CHAT_MODEL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Structured Output: ì£¼ì œ â†’ í”„ë¡œì íŠ¸ ë¸Œë¦¬í”„ ìŠ¤í‚¤ë§ˆ\n",
        "í•™ìƒì´ ì…ë ¥í•œ **ì£¼ì œ/ë²”ìœ„/ì‚°ì¶œë¬¼ ê¸°ëŒ€ì¹˜** ë“±ì„ êµ¬ì¡°í™”í•´ì„œ, ì´í›„ ë‹¨ê³„ë“¤ì˜ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class ProjectBrief(BaseModel):\n",
        "    topic: str\n",
        "    goals: List[str]\n",
        "    deliverables: List[str]\n",
        "    constraints: List[str]\n",
        "\n",
        "user_topic = \"í•œêµ­ ë°˜ë„ì²´ ì‚°ì—…ì—ì„œ AIê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥ (200ì ì´ë‚´ ê°œìš”)\"\n",
        "\n",
        "brief_resp = client.responses.parse(\n",
        "    model=CHAT_MODEL,\n",
        "    input=[\n",
        "        {\"role\": \"developer\", \"content\": \"ë‹¤ìŒ ì…ë ¥ì„ í”„ë¡œì íŠ¸ ë¸Œë¦¬í”„ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”.\"},\n",
        "        {\"role\": \"user\", \"content\": user_topic},\n",
        "    ],\n",
        "    text_format=ProjectBrief,\n",
        ")\n",
        "project_brief = brief_resp.output_parsed\n",
        "print(\"[Project Brief]\", brief_resp.output_text)  # JSON ë¬¸ìì—´\n",
        "project_brief\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Conversation State: ì´ì „ ì‘ë‹µ IDë¥¼ ì´ìš©í•´ ë¬¸ë§¥ ì‡ê¸°\n",
        "êµ¬ì¡°í™”ëœ ë¸Œë¦¬í”„ë¥¼ ì´ì–´ë°›ì•„, ì„¸ë¶€ ë¦¬ì„œì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "checklist_resp = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"ì „ë¬¸ ì—°êµ¬ ì¡°êµë¡œì„œ ê°„ê²°í•˜ê³  ì‹¤í–‰ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì œì‹œí•˜ì„¸ìš”.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"í”„ë¡œì íŠ¸ ë¸Œë¦¬í”„: {project_brief.json(ensure_ascii=False)}\"},\n",
        "    ],\n",
        ")\n",
        "previous_response_id = checklist_resp.id\n",
        "print(checklist_resp.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Web Search: ìµœì‹  ì¶œì²˜ ìˆ˜ì§‘ + ê°„ë‹¨ ìš”ì•½\n",
        "ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ í™œì„±í™”í•˜ì—¬, í•µì‹¬ ì¶œì²˜ 3~5ê°œë¥¼ ì°¾ê³  í•œ ë¬¸ë‹¨ ìš”ì•½ì„ ë°›ìŠµë‹ˆë‹¤.\n",
        "ë°˜í™˜ ê°ì²´ì— **sources**ë¥¼ í¬í•¨ì‹œì¼œ ê°€ë³ê²Œ ì¸ìš© ëª©ë¡ì„ ì‚´í´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "web_query = f\"{project_brief.topic} ê´€ë ¨ ìµœì‹  ë™í–¥ê³¼ í•µì‹¬ ì¶œì²˜ 3~5ê°œ\"\n",
        "web_resp = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    tools=[{\"type\": \"web_search\"}],\n",
        "    input=[\n",
        "        {\"role\": \"user\", \"content\": web_query}\n",
        "    ],\n",
        "    include=[\"web_search_call.action.sources\"],\n",
        "    previous_response_id=previous_response_id,\n",
        ")\n",
        "previous_response_id = web_resp.id\n",
        "print(web_resp.output_text)\n",
        "\n",
        "# (ì„ íƒ) ì†ŒìŠ¤ URL ë¯¸ë‹ˆ ë¦¬ìŠ¤íŠ¸\n",
        "sources = []\n",
        "for item in getattr(web_resp, \"output\", []) or []:\n",
        "    if getattr(item, \"type\", \"\") == \"web_search_call\":\n",
        "        action = getattr(item, \"action\", None)\n",
        "        if action and getattr(action, \"sources\", None):\n",
        "            for s in action.sources[:5]:\n",
        "                sources.append(getattr(s, \"url\", \"\"))\n",
        "print(\"\\n[Top Sources]\")\n",
        "for u in sources:\n",
        "    print(\"-\", u)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) File Search / Vector Store (RAG): ë¡œì»¬ í´ë” ì¸ë±ì‹± â†’ ì§ˆì˜\n",
        "- ì•„ë˜ ì…€ì—ì„œ `DATA_DIR` ê²½ë¡œì— PDF/TXT/MD/CSVë¥¼ ë„£ì–´ë‘ë©´, í•´ë‹¹ íŒŒì¼ì„ **ë²¡í„° ìŠ¤í† ì–´**ë¡œ ì—…ë¡œë“œí•˜ê³ \n",
        "  `file_search` ë„êµ¬ë¡œ ì§ˆì˜í•©ë‹ˆë‹¤.\n",
        "- ê°•ì˜ì—ì„œëŠ” ì‘ì€ TXT/MD ì—¬ëŸ¬ ê°œë¡œ ë¹ ë¥´ê²Œ ì‹¤ìŠµí•˜ê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import glob\n",
        "\n",
        "DATA_DIR = \"./data\"  # ì‹¤ìŠµ ì‹œ ì›í•˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# 1) ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
        "vs = client.vector_stores.create(name=\"Integrated-Notebook-KB\")\n",
        "vector_store_id = vs.id\n",
        "print(\"Vector Store:\", vector_store_id)\n",
        "\n",
        "# 2) ì—…ë¡œë“œí•  íŒŒì¼ ìˆ˜ì§‘\n",
        "paths = []\n",
        "for ext in (\"*.pdf\", \"*.txt\", \"*.md\", \"*.csv\"):\n",
        "    paths.extend(glob.glob(os.path.join(DATA_DIR, ext)))\n",
        "\n",
        "if paths:\n",
        "    streams = [open(p, \"rb\") for p in paths]\n",
        "    try:\n",
        "        batch = client.vector_stores.file_batches.upload_and_poll(\n",
        "            vector_store_id=vector_store_id, files=streams\n",
        "        )\n",
        "        print(\"Upload Status:\", getattr(batch, \"status\", \"?\"))\n",
        "    finally:\n",
        "        for s in streams:\n",
        "            try: s.close()\n",
        "            except: pass\n",
        "else:\n",
        "    print(\"ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. data í´ë”ì— ìë£Œë¥¼ ë„£ìœ¼ë©´ ì¬ì‹¤í–‰í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rag_question = f\"{project_brief.topic}ì— ëŒ€í•œ ìš”ì•½ì„ ìš°ë¦¬ ìë£Œ ê¸°ë°˜ìœ¼ë¡œ 5ë¬¸ì¥ ì´ë‚´ë¡œ ì œì‹œí•˜ê³ , ì°¸ì¡°í•œ íŒŒì¼ëª…ì„ ë‚˜ì—´í•˜ì„¸ìš”.\"\n",
        "rag_resp = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    instructions=\"ì œê³µëœ file_search ì¶œì²˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•˜ì„¸ìš”.\",\n",
        "    input=rag_question,\n",
        "    tools=[{\"type\": \"file_search\", \"vector_store_ids\": [vector_store_id]}],\n",
        "    include=[\"file_search_call.results\"],\n",
        ")\n",
        "previous_response_id = rag_resp.id\n",
        "print(rag_resp.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Code Interpreter: ê°„ë‹¨í•œ ë°ì´í„° ì‹¤í—˜/ì‹œê°í™”\n",
        "ì˜ˆì‹œë¡œ **ê°€ìƒì˜ ì›”ë³„ ìƒì‚°ëŸ‰ CSV**ë¥¼ ë§Œë“¤ì–´ í†µê³„/ì‹œê°í™”ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.\n",
        "ê°•ì˜ì—ì„œëŠ” ì´ ë¶€ë¶„ë§Œ êµì²´í•´ ìˆ˜ì¹˜ ì‹¤í—˜ ê³¼ì œë¥¼ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ci_instruction = (\n",
        "    \"ì›”ë³„ ë°˜ë„ì²´ ìƒì‚°ëŸ‰(ê°€ìƒ) CSVë¥¼ ìƒì„±í•˜ê³ , ì—°í‰ê· /ìµœëŒ“ê°’/ìµœì†Ÿê°’ì„ ê³„ì‚°í•œ ë’¤, \"\n",
        "    \"matplotlibë¡œ ë‹¨ì¼ ì„ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ PNGë¡œ ì €ì¥í•˜ê³  ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ì„¸ìš”.\"\n",
        ")\n",
        "ci_resp = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    tools=[{\"type\": \"code_interpreter\", \"container\": {\"type\": \"auto\"}}],\n",
        "    tool_choice=\"required\",\n",
        "    input=ci_instruction,\n",
        ")\n",
        "previous_response_id = ci_resp.id\n",
        "print(ci_resp.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Function Calling: ë³´ì¡° ë„êµ¬(ì˜ˆ: ë‚ ì”¨) ê²°í•© â†’ ìµœì¢… ìš”ì•½\n",
        "ì—°êµ¬ ë°°ê²½ ì„¤ëª…ì„ ìœ„í•´ íŠ¹ì • ì§€ì—­(ì˜ˆ: **Seoul**)ì˜ ë‚ ì”¨ë¥¼ **í•¨ìˆ˜ í˜¸ì¶œ**ë¡œ ê°€ì ¸ì™€\n",
        "ê²°ë¡  ìš”ì•½ì— ë°˜ì˜í•˜ëŠ” ì˜ˆë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_current_weather(location: str, unit: str = \"celsius\") -> str:\n",
        "    # ì‹¤ìŠµìš© ë”ë¯¸\n",
        "    data = {\"location\": location, \"temperature\": \"unknown\", \"unit\": unit}\n",
        "    low = location.lower()\n",
        "    if \"seoul\" in low or \"ì„œìš¸\" in low:\n",
        "        data[\"temperature\"] = \"14\"\n",
        "    return json.dumps(data, ensure_ascii=False)\n",
        "\n",
        "TOOLS = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"ê°„ë‹¨í•œ í˜„ì¬ ë‚ ì”¨(ë”ë¯¸)ë¥¼ ë°˜í™˜\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\"type\": \"string\"},\n",
        "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "# 1ì°¨ í˜¸ì¶œ: ë„êµ¬ ì‚¬ìš© ìœ ë„\n",
        "fc1 = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    tools=TOOLS,\n",
        "    input=[{\"role\": \"user\", \"content\": \"ì„œìš¸ì˜ í˜„ì¬ ê¸°ì˜¨ì„ ì•Œë ¤ì£¼ê³ , ì—°êµ¬ ë§¥ë½ ìš”ì•½ì— ì°¸ê³ í•´ì¤˜.\"}],\n",
        ")\n",
        "\n",
        "inputs = fc1.output.copy()\n",
        "for item in fc1.output:\n",
        "    if getattr(item, \"type\", \"\") == \"function_call\":\n",
        "        if item.name == \"get_current_weather\":\n",
        "            args = json.loads(item.arguments or \"{}\")\n",
        "            out = get_current_weather(args.get(\"location\", \"Seoul\"), args.get(\"unit\", \"celsius\"))\n",
        "            inputs.append({\n",
        "                \"type\": \"function_call_output\",\n",
        "                \"call_id\": item.call_id,\n",
        "                \"output\": json.dumps({\"weather\": out}, ensure_ascii=False),\n",
        "            })\n",
        "\n",
        "# ìµœì¢… ìš”ì•½: ì•ì„  ì›¹/RAG/ì½”ë“œ ê²°ê³¼ì™€ ë‚ ì”¨ë¥¼ ë¬¶ì–´ ê°„ë‹¨ ê²°ë¡  ë„ì¶œ\n",
        "fc2 = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    tools=TOOLS,\n",
        "    instructions=(\n",
        "        \"ì§€ê¸ˆê¹Œì§€ì˜ ì›¹/RAG/ì½”ë“œ ì¸í„°í”„ë¦¬í„° ê²°ê³¼ì™€ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, \"\n",
        "        \"ì—°êµ¬ ì£¼ì œì— ëŒ€í•œ 5ë¬¸ì¥ ë‚´ ê²°ë¡ ì„ í•œêµ­ì–´ë¡œ ì œì‹œí•˜ì„¸ìš”.\"\n",
        "    ),\n",
        "    input=inputs,\n",
        "    previous_response_id=previous_response_id,\n",
        ")\n",
        "previous_response_id = fc2.id\n",
        "print(fc2.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Streaming: ìµœì¢… ë³´ê³ ì„œ(í•µì‹¬ ìš”ì•½) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
        "ì•ì„œ ì¶•ì ëœ ëŒ€í™” ìƒíƒœë¥¼ í™œìš©í•´, í† í° ë‹¨ìœ„ë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” ì˜ˆì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stream_prompt = (\n",
        "    \"ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•µì‹¬ë§Œ ì¶”ë¦° 3ë¬¸ì¥ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”. \"\n",
        "    \"ì „ë¬¸ ìš©ì–´ëŠ” ìµœì†Œí™”í•˜ê³ , ë¶ˆë¦¿ ì—†ì´ ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±.\"\n",
        ")\n",
        "\n",
        "stream = client.responses.create(\n",
        "    model=CHAT_MODEL,\n",
        "    input=[{\"role\": \"user\", \"content\": stream_prompt}],\n",
        "    stream=True,\n",
        "    previous_response_id=previous_response_id,\n",
        ")\n",
        "print(\"[Streaming] \", end=\"\", flush=True)\n",
        "for chunk in stream:\n",
        "    if getattr(chunk, \"type\", \"\") == \"response.output_text.delta\":\n",
        "        print(chunk.delta, end=\"\", flush=True)\n",
        "print(\"\\n[done]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë§ˆë¬´ë¦¬ ë° ê³¼ì œ ì•„ì´ë””ì–´\n",
        "- **ì£¼ì œ êµì²´**: ììœ  ì£¼ì œë¡œ ë°”ê¾¸ê³ , ë¸Œë¦¬í”„/ì²´í¬ë¦¬ìŠ¤íŠ¸/ì›¹/RAG/ì½”ë“œ/ë„êµ¬/ìŠ¤íŠ¸ë¦¬ë°ì„ ì¬ì‹¤í–‰\n",
        "- **RAG ê°•ì˜**: `data/` í´ë”ì— ìˆ˜ì—… ìë£Œ(TXT/MD) ì¶”ê°€ â†’ ëª¨ë¸ ê·¼ê±° ì‘ë‹µ ë¹„êµ\n",
        "- **ì½”ë“œ ì¸í„°í”„ë¦¬í„° í™•ì¥**: ì‹¤ì œ CSV/ì—‘ì…€ì„ ì—…ë¡œë“œí•´ í†µê³„/ì‹œê°í™” ê³¼ì œ ë§Œë“¤ê¸°\n",
        "- **í•¨ìˆ˜ í˜¸ì¶œ íˆ´í‚·**: ë‰´ìŠ¤ í—¤ë“œë¼ì¸ íŒŒì„œ, ê°„ì´ í™˜ìœ¨ ê³„ì‚°ê¸° ë“± ì»¤ìŠ¤í…€ ë„êµ¬ ì¶”ê°€\n",
        "- **í‰ê°€ ë£¨ë¸Œë¦­**: êµ¬ì¡°í™” ì¶œë ¥(JSON)ìœ¼ë¡œ ì‚°ì¶œë¬¼ì˜ í˜•ì‹ ê²€ì¦ ìë™í™”\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}